{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the `Yelp` Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.utils import check_consistent_length\n",
    "\n",
    "\n",
    "CORE = 10\n",
    "SEED = 0\n",
    "DATA_DIR = (\n",
    "    Path()\n",
    "    .cwd()\n",
    "    .parent.joinpath(\"data\", \"processed\", \"yelp\", f\"core_{CORE}_seed_{SEED}\")\n",
    ")\n",
    "assert DATA_DIR.is_dir()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "Edges between users are undirected, and `edge_uu.txt` only stores the indices of the upper triangular part of the adjacency matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `ratings`: a 2d `numpy.ndarray` object.\n",
    "# Each row is a `[uid, iid, label]` triplet.\n",
    "ratings = np.unique(\n",
    "    np.loadtxt(DATA_DIR.joinpath(\"ratings.txt\"), dtype=np.int64), axis=0\n",
    ")\n",
    "# `triplets_kg`: a 2d `numpy.ndarray` object.\n",
    "# Each row is a `[eid_h, rid, eid_t]` triplet.\n",
    "triplets_kg = np.unique(\n",
    "    np.loadtxt(DATA_DIR.joinpath(\"triplets_kg.txt\"), dtype=np.int64), axis=0\n",
    ")\n",
    "# `edges_user`: a 2d `numpy.ndarray` object.\n",
    "# Each row is an unordered `[uid_u, uid_v]` pair.\n",
    "edges_user = np.unique(\n",
    "    np.loadtxt(DATA_DIR.joinpath(\"edges_uu.txt\"), dtype=np.int64), axis=0\n",
    ")\n",
    "assert ratings.ndim == 2 and ratings.shape[1] == 3\n",
    "assert triplets_kg.ndim == 2 and triplets_kg.shape[1] == 3\n",
    "assert edges_user.ndim == 2 and edges_user.shape[1] == 2\n",
    "# indices of the upper triangular part of the adjacency matrix\n",
    "assert np.all(edges_user[:, 0] < edges_user[:, 1])\n",
    "print(\n",
    "    \"\\n\".join(\n",
    "        [\n",
    "            f\"num_ratings = {ratings.shape[0]}\",\n",
    "            f\"num_triplets = {triplets_kg.shape[0]}\",\n",
    "            f\"num_edges_user = {edges_user.shape[0]}\",\n",
    "        ]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ratings[:, 0].max() + 1\n",
    "num_items = ratings[:, 1].max() + 1\n",
    "num_entities = triplets_kg[:, [0, 2]].max() + 1\n",
    "num_relations = triplets_kg[:, 1].max() + 1\n",
    "assert num_items < num_entities\n",
    "assert edges_user.max() < num_users\n",
    "sparsity_ui = ratings.shape[0] / num_users / num_items\n",
    "sparsity_uu = edges_user.shape[0] * 2 / num_users / (num_users - 1)\n",
    "print(\n",
    "    \"\\n\".join(\n",
    "        [\n",
    "            f\"num_users = {num_users}\",\n",
    "            f\"num_items = {num_items}\",\n",
    "            f\"num_entities = {num_entities}\",\n",
    "            f\"num_relations = {num_relations}\",\n",
    "            f\"sparsity_ui = {sparsity_ui}\",\n",
    "            f\"sparsity_uu = {sparsity_uu}\",\n",
    "        ]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Item Interaction Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodes user history to a vector\n",
    "# `user_history` is a `nnumpy.ndarray` object of shape `[num_users, num_items]`\n",
    "# For each positive sample `(uid, iid)`, `user_history[uid, iid] = 1`.\n",
    "ratings_pos = ratings[ratings[:, 2] == 1]\n",
    "user_history = sp.csr_matrix(\n",
    "    ([1.0] * ratings_pos.shape[0], (ratings_pos[:, 0], ratings_pos[:, 1])),\n",
    "    shape=(num_users, num_items),\n",
    "    dtype=np.float32,\n",
    ")\n",
    "user_history.nnz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_u = user_history.sum(axis=1).A.flatten()\n",
    "deg_i = user_history.sum(axis=0).A.flatten()\n",
    "print(\n",
    "    \"\\n\".join(\n",
    "        [\n",
    "            f\"deg_u: mean = {np.mean(deg_u)}, std = {np.std(deg_u)}\",\n",
    "            f\"deg_i: mean = {np.mean(deg_i)}, std = {np.std(deg_i)}, \",\n",
    "        ]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(deg_u, return_counts=True), np.unique(deg_i, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity between Users Connected by Social Edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Common Neighbors & Jaccard Measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_neighbors_jaccard(\n",
    "    y_true: sp.spmatrix, y_pred: sp.spmatrix\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    assert y_true.ndim == 2 and y_pred.ndim == 2\n",
    "    check_consistent_length(y_true, y_pred)\n",
    "    y_true = y_true.astype(np.bool_).astype(np.int8)\n",
    "    y_pred = y_pred.astype(np.bool_).astype(np.int8)\n",
    "    union = y_true.multiply(y_pred)\n",
    "    intersection = (y_true + y_pred).astype(np.bool_).astype(np.int8)\n",
    "    num_union = union.sum(axis=1).A.astype(np.float32)\n",
    "    num_intersection = intersection.sum(axis=1).A.astype(np.float32)\n",
    "    return num_union, num_union / num_intersection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `common_nbrs_pos`: the number of common neighbors between users\n",
    "# connected by edges\n",
    "# `jaccard_pos`: the jaccard measure between users connected by edges\n",
    "common_nbrs_pos, jaccard_pos = common_neighbors_jaccard(\n",
    "    user_history[edges_user[:, 0], :], user_history[edges_user[:, 1], :]\n",
    ")\n",
    "print(\n",
    "    \"\\n\".join(\n",
    "        [\n",
    "            f\"common_nbrs_pos: mean = {np.mean(common_nbrs_pos)}, \"\n",
    "            f\"std = {np.std(common_nbrs_pos)}, \"\n",
    "            f\"median = {np.median(common_nbrs_pos)}\",\n",
    "            f\"jaccard_pos: mean = {np.mean(jaccard_pos)}, \"\n",
    "            f\"std = {np.std(jaccard_pos)}, \"\n",
    "            f\"median = {np.median(jaccard_pos)}\",\n",
    "        ]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the Yelp dataset, edges are undirected.\n",
    "# The number of possible edges is N = `(num_users - 1) * num_users / 2``\n",
    "def encode_indices_batch(rows: np.ndarray, cols: np.ndarray) -> np.ndarray:\n",
    "    # converts a `(row, col)` pair to [0, N - 1]\n",
    "    assert np.all(rows < cols)\n",
    "    return rows + cols * (cols - 1) // 2\n",
    "\n",
    "\n",
    "def decode_indices_batch(\n",
    "    indices: np.ndarray, size: int\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # converts an integer in the range [0, N - 1] to a `(row, col)` pair\n",
    "    bins = np.cumsum(np.arange(size))\n",
    "    cols = np.digitize(indices, bins, right=False)\n",
    "    rows = indices - cols * (cols - 1) // 2\n",
    "    return rows, cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_pos = encode_indices_batch(edges_user[:, 0], edges_user[:, 1])\n",
    "assert np.unique(indices_pos).size == indices_pos.size\n",
    "population = (num_users) * (num_users - 1) // 2\n",
    "\n",
    "# samples a set of negative edges to compute the number of common neighbors\n",
    "# and the jaccard measure of users that are not connected since the population\n",
    "# is too large\n",
    "num_neg = indices_pos.size\n",
    "num_samples = int(1.2 * num_neg)\n",
    "\n",
    "max_trial = 3\n",
    "num_runs = 100\n",
    "\n",
    "common_nbrs_neg_per_run = []\n",
    "jaccard_neg_per_run = []\n",
    "for _ in range(num_runs):\n",
    "    # sample negative edges\n",
    "    indices_neg = None\n",
    "    for _ in range(max_trial):\n",
    "        samples = np.unique(\n",
    "            np.random.randint(population, size=num_samples, dtype=np.int64)\n",
    "        )\n",
    "        mask = np.isin(samples, indices_pos, invert=True)\n",
    "        if indices_neg is not None:\n",
    "            mask = np.logical_and(\n",
    "                mask, np.isin(samples, indices_neg, invert=True)\n",
    "            )\n",
    "        samples = samples[mask]\n",
    "        indices_neg = (\n",
    "            samples\n",
    "            if indices_neg is None\n",
    "            else np.hstack([indices_neg, samples])\n",
    "        )\n",
    "        if indices_neg.size >= num_neg:\n",
    "            indices_neg = indices_neg[:num_neg]\n",
    "            break\n",
    "    assert indices_neg.size == num_neg\n",
    "    assert np.unique(indices_neg).size == indices_neg.size\n",
    "    assert np.all(np.isin(indices_neg, indices_pos, invert=True))\n",
    "\n",
    "    rows, cols = decode_indices_batch(indices_neg, size=num_users)\n",
    "    assert np.all(rows < cols)\n",
    "\n",
    "    # `common_nbrs_neg`: the number of common neighbors between users\n",
    "    # that are not connected\n",
    "    # `jaccard_neg`: the jaccard measure between users that are not connected\n",
    "    common_nbrs_neg, jaccard_neg = common_neighbors_jaccard(\n",
    "        user_history[rows, :], user_history[cols, :]\n",
    "    )\n",
    "    common_nbrs_neg_per_run.append(np.mean(common_nbrs_neg))\n",
    "    jaccard_neg_per_run.append(np.mean(jaccard_neg))\n",
    "\n",
    "print(\n",
    "    \"\\n\".join(\n",
    "        [\n",
    "            f\"common_nbrs_neg: mean = {np.mean(common_nbrs_neg_per_run)}, \"\n",
    "            f\"std = {np.std(common_nbrs_neg_per_run)}\",\n",
    "            f\"jaccard_neg: mean = {np.mean(jaccard_neg_per_run)}, \"\n",
    "            f\"std = {np.std(jaccard_neg_per_run)}\",\n",
    "        ]\n",
    "    )\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98215ffbdaf5e807ce7896eb846bcd2d1ce71c3892f0b2e8a92fbe7dc26fa398"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('pytorch_dgl': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
